{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd48a054-608e-4a3e-87d8-6eaf1bb747d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator                                                                           \n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153898ef-2c5c-42ce-be40-a11ee3be27bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory containing numeric subdirectories\n",
    "base_dir = Path(r'C:\\Users\\samir\\Desktop\\Zahraa\\CMPS 261\\Project\\data')\n",
    "\n",
    "# Mapping of indices to folder names (indices are the actual folder names)\n",
    "categories = {\n",
    "    1: \"bottle\",\n",
    "    2: \"basket\",\n",
    "    3: \"food\",\n",
    "    4: \"cup\",\n",
    "    5: \"jar\",\n",
    "    6: \"can\",\n",
    "    7: \"dish\",\n",
    "    8: \"mug\",\n",
    "    9: \"glass\"\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store file paths for each category\n",
    "category_files = {index: [] for index in categories}\n",
    "\n",
    "# Populate the dictionary with the file paths from the indexed folders\n",
    "for index in categories:\n",
    "    category_dir = base_dir / str(index)  # Numeric subdirectory name\n",
    "    if category_dir.exists() and os.path.isdir(category_dir):\n",
    "        # Collect all .jpg files under this directory\n",
    "        category_files[index] = list(category_dir.rglob('*.jpg'))\n",
    "    else:\n",
    "        print(f\"Warning: Directory not found or is not a directory: {category_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbdf27f-1864-4294-8ee6-2b8380c10910",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "\n",
    "for index, files in category_files.items():\n",
    "    if files:\n",
    "        train_files.extend(files)\n",
    "\n",
    "# Print the number of files in the training set\n",
    "print(f'Number of training files: {len(train_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f096db-0b5c-4661-a8de-04da0ec0629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames for training and testing sets\n",
    "def create_dataframe(files, categories):\n",
    "    data = []\n",
    "    for file_path in files:\n",
    "        index = int(Path(file_path).parent.name)\n",
    "        label = categories.get(index, \"Unknown\")\n",
    "        data.append({\"Filepath\": file_path, \"Label\": label})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "train_df = create_dataframe(train_files, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed5bd49-d632-48f4-b131-1710ffb8e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.2,  # Increase zoom range\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],  # Adjust brightness\n",
    "    fill_mode=\"nearest\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334c6a7b-7aac-4aab-abf4-630066783519",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Filepath'] = train_df['Filepath'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbfe4c-5a7b-4322-812f-b3b00159d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm correct data generators for each dataset\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ec8d17-bb82-4c00-80b3-7ad9122a0716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load the pre-trained MobileNetV2 model, excluding the top layer\n",
    "pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),  # Adjust input shape to match image shape\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    pooling='avg'  # Pooling to obtain a feature vector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae67707-0d81-4752-8134-32d85ad4d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the pre-trained layers\n",
    "pretrained_model.trainable = False\n",
    "inputs = pretrained_model.input\n",
    "\n",
    "x = pretrained_model.output  # Output of pre-trained model\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# Adjust the output layer to the number of classes in your dataset\n",
    "outputs = tf.keras.layers.Dense(9, activation='softmax')(x)\n",
    "\n",
    "# Create the final model by combining input and output layers\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb11def6-2ecf-4d25-bd9d-19b9b451b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the training and validation data generators\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    epochs=10,  # Adjust epochs as needed\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='loss',\n",
    "            patience=2,\n",
    "            restore_best_weights=True  # Restore weights of the best epoch based on loss\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Save the weights of the best epoch based on training loss\n",
    "best_weights = model.get_weights()\n",
    "# Set the model's weights to the best weights obtained during training\n",
    "model.set_weights(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ee765-49ec-44dc-8edc-aafaa24a2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load and preprocess all images in a directory\n",
    "def load_and_preprocess_images(directory_path):\n",
    "    # Initialize an empty list to store preprocessed images\n",
    "    img_list = []\n",
    "    \n",
    "    # Iterate over each file in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # Construct the full path to the image file\n",
    "        img_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Load and resize the image\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        \n",
    "        # Convert the image to a numpy array\n",
    "        img_array = image.img_to_array(img)\n",
    "        \n",
    "        # Preprocess the image for MobileNetV2\n",
    "        img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
    "        \n",
    "        # Append the processed image array to the list\n",
    "        img_list.append(img_array)\n",
    "    \n",
    "    # Convert list of arrays to a single numpy array\n",
    "    img_batch = np.array(img_list)\n",
    "    return img_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b291a24c-483f-4a9b-92d3-7445b1907a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classes of images\n",
    "def predict_image_classes(model, img_batch):\n",
    "    predictions = model.predict(img_batch)\n",
    "    class_indices = np.argmax(predictions, axis=1)\n",
    "    return class_indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
